
@manual{hahsler_recommenderlab_2020,
  title  = {recommenderlab: Lab for Developing and Testing Recommender Algorithms},
  author = {Michael Hahsler},
  year   = {2020},
  note   = {R package version 0.2-6},
  url    = {https://github.com/mhahsler/recommenderlab}
}

@article{audigier_principal_2013,
  title   = {A principal components method to impute missing values for mixed data},
  url     = {http://arxiv.org/abs/1301.4797},
  urldate = {2020-11-01},
  journal = {arXiv:1301.4797 [stat]},
  author  = {Audigier, Vincent and Husson, Fran√ßois and Josse, Julie},
  month   = feb,
  year    = {2013}
}

@techreport{hastie_imputing_1999,
  title  = {Imputing missing data for gene expression arrays},
  author = {Hastie, Trevor and Tibshirani, Robert and Sherlock, Gavin and Eisen, Michael and Brown, Patrick and Botstein, David},
  year   = {1999}
}

@misc{hilla_titanic_2017,
  title    = {Titanic {Analysis} with {R}},
  author   = {Hilla Behar},
  url      = {https://kaggle.com/hillabehar/titanic-analysis-with-r},
  abstract = {Explore and run machine learning code with Kaggle Notebooks {\textbar} Using data from Titanic: Machine Learning from Disaster},
  language = {en},
  urldate  = {2020-11-19},
  year     = {2017},
  file     = {Snapshot:C\:\\Users\\meetz\\Zotero\\storage\\Q69V2CJ7\\titanic-analysis-with-r.html:text/html}
}

@misc{kaggle_titanic_2015,
  title      = {Titanic: {Machine} {Learning} from {Disaster}},
  author     = {kaggle.com},
  shorttitle = {Titanic},
  url        = {https://kaggle.com/c/titanic},
  abstract   = {Start here! Predict survival on the Titanic and get familiar with ML basics},
  language   = {en},
  urldate    = {2020-11-19},
  year       = {2015}
}

@article{kiers_weighted_1997,
  title   = {Weighted least squares fitting using ordinary least squares algorithms},
  volume  = {62},
  issn    = {1860-0980},
  url     = {https://doi.org/10.1007/BF02295279},
  doi     = {10.1007/BF02295279},
  number  = {2},
  urldate = {2020-11-15},
  journal = {Psychometrika},
  author  = {Kiers, Henk A. L.},
  month   = jun,
  year    = {1997},
  pages   = {251--266}
}


@book{little_statistical_2019,
  title     = {Statistical {Analysis} with {Missing} {Data}},
  isbn      = {978-0-470-52679-8},
  publisher = {John Wiley \& Sons},
  author    = {Little, Roderick J. A. and Rubin, Donald B.},
  month     = apr,
  year      = {2019}
}

@article{ma_missing_2019,
  title      = {Missing {Not} at {Random} in {Matrix} {Completion}: {The} {Effectiveness} of {Estimating} {Missingness} {Probabilities} {Under} a {Low} {Nuclear} {Norm} {Assumption}},
  shorttitle = {Missing {Not} at {Random} in {Matrix} {Completion}},
  url        = {http://arxiv.org/abs/1910.12774},
  urldate    = {2020-11-08},
  journal    = {arXiv:1910.12774 [cs, stat]},
  author     = {Ma, Wei and Chen, George H.},
  month      = oct,
  year       = {2019}
}

@article{ramazanli_optimal_2020,
  title   = {Optimal {Adaptive} {Matrix} {Completion}},
  url     = {http://arxiv.org/abs/2002.02431},
  urldate = {2020-11-01},
  journal = {arXiv:2002.02431 [cs, stat]},
  author  = {ramazanli, Ilqar and Poczos, Barnabas},
  month   = feb,
  year    = {2020}
}


@article{sportisse_imputation_2020,
  title   = {Imputation and low-rank estimation with {Missing} {Not} {At} {Random} data},
  url     = {http://arxiv.org/abs/1812.11409},
  urldate = {2020-11-08},
  journal = {arXiv:1812.11409 [cs, stat]},
  author  = {Sportisse, Aude and Boyer, Claire and Josse, Julie},
  month   = jan,
  year    = {2020}
}


@article{stekhoven_missforest--non-parametric_2012,
  title   = {{MissForest}--non-parametric missing value imputation for mixed-type data},
  volume  = {28},
  issn    = {1367-4803, 1460-2059},
  url     = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/btr597},
  doi     = {10.1093/bioinformatics/btr597},
  number  = {1},
  urldate = {2020-11-08},
  journal = {Bioinformatics},
  author  = {Stekhoven, D. J. and Buhlmann, P.},
  month   = jan,
  year    = {2012},
  pages   = {112--118}
}

@article{troyanskaya_missing_2001,
  title   = {Missing value estimation methods for {DNA} microarrays},
  volume  = {17},
  issn    = {1367-4803, 1460-2059},
  url     = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/17.6.520},
  doi     = {10.1093/bioinformatics/17.6.520},
  number  = {6},
  urldate = {2020-11-08},
  journal = {Bioinformatics},
  author  = {Troyanskaya, O. and Cantor, M. and Sherlock, G. and Brown, P. and Hastie, T. and Tibshirani, R. and Botstein, D. and Altman, R. B.},
  month   = jun,
  year    = {2001},
  pages   = {520--525}
}

@article{zhu_high-dimensional_2019,
  title   = {High-dimensional principal component analysis with heterogeneous missingness},
  url     = {http://arxiv.org/abs/1906.12125},
  urldate = {2020-11-01},
  journal = {arXiv:1906.12125 [math, stat]},
  author  = {Zhu, Ziwei and Wang, Tengyao and Samworth, Richard J.},
  month   = jun,
  year    = {2019}
}

@misc{mazumder_softimpute_2015,
	title = {{softImpute}: {Matrix} {Completion} via {Iterative} {Soft}-{Thresholded} {SVD}},
	copyright = {GPL-2},
	shorttitle = {{softImpute}},
	url = {https://CRAN.R-project.org/package=softImpute},
	abstract = {Iterative methods for matrix completion that use nuclear-norm regularization. There are two main approaches.The one approach uses iterative soft-thresholded svds to impute the missing values. The second approach uses alternating least squares. Both have an "EM" flavor, in that at each iteration the matrix is completed with the current estimate. For large matrices there is a special sparse-matrix class named "Incomplete" that efficiently handles all computations. The package includes procedures for centering and scaling rows, columns or both, and for computing low-rank SVDs on large sparse centered matrices (i.e. principal components)},
	urldate = {2020-11-20},
	author = {Mazumder, Trevor Hastie {and} Rahul},
	month = apr,
	year = {2015}
}
